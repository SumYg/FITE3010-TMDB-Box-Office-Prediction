{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def convert_list_of_dict_str_to_list_of_dict(x):\n",
    "    if isinstance(x, str):\n",
    "        return eval(x)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# multilingual_model = SentenceTransformer('paraphrase-xlm-r-multilingual-v1')\n",
    "multilingual_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(column):\n",
    "    df[column] = df[column].apply(convert_list_of_dict_str_to_list_of_dict)\n",
    "    \n",
    "    # for i in df[column].iloc[:15]:\n",
    "    #     print(i, len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "from datetime import timedelta\n",
    "def check_if_is_holiday(dt, country_code):\n",
    "    # if country_code == 'IN' and dt.year <= 2001:\n",
    "    #     return False\n",
    "    return dt.date() in holidays.CountryHoliday(country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = ['CN', 'US', 'KR', 'IN', 'GB', 'FR', 'DE', 'ES', 'RU', 'AU', 'CA', 'MX', 'BR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['belongs_to_collection'] = df['belongs_to_collection'].apply(convert_list_of_dict_str_to_list_of_dict)\n",
    "collections = [d[0]['name'] if d else '' for d in df['belongs_to_collection'].tolist()]\n",
    "embeddings = multilingual_model.encode(collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a empty numpy array\n",
    "features = np.empty((len(df), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, embeddings), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['budget'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 769)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, df['budget'].values.reshape(-1, 1)), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].apply(convert_list_of_dict_str_to_list_of_dict)\n",
    "genres = [Counter([o['id'] for o in d])  for d in df['genres']]\n",
    "genres_vectorizer = DictVectorizer(dtype=int)\n",
    "\n",
    "genres_vectorizer.fit(genres)\n",
    "\n",
    "genres_vectors = genres_vectorizer.transform(genres).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 789)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, genres_vectors), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_language = df['original_language'].values\n",
    "original_language = original_language.reshape(-1, 1)\n",
    "\n",
    "original_language_ohe = OneHotEncoder(min_frequency=.005, sparse_output=False, handle_unknown='infrequent_if_exist').fit(original_language)\n",
    "original_language_ohe.transform(original_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 802)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, original_language_ohe.transform(original_language)), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = multilingual_model.encode(df['original_title'].values)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1570)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, embeddings), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overview'] = df['overview'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = multilingual_model.encode(df['overview'].values)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2338)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, embeddings), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2339)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, df['popularity'].values.reshape(-1, 1)), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 80)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert('production_companies')\n",
    "production_companies = [[str(o['name']) for o in d]  for d in df['production_companies'].tolist()]\n",
    "feature_hasher = FeatureHasher(n_features=80, input_type=\"string\")\n",
    "production_companies_features = feature_hasher.transform(production_companies)  # can be id\n",
    "production_companies_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2419)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, production_companies_features.toarray()), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 80)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert('production_countries')\n",
    "production_companies = [[str(o['iso_3166_1']) for o in d]  for d in df['production_countries'].tolist()]\n",
    "feature_hasher = FeatureHasher(n_features=80, input_type=\"string\")\n",
    "production_companies_features = feature_hasher.transform(production_companies)  # can be id\n",
    "production_companies_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2499)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, production_companies_features.toarray()), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date into day, month, year, weekday\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], format='%m/%d/%y')\n",
    "df[\"release_date\"] = df[\"release_date\"].apply(lambda x: x - relativedelta(years=100) if x.year > 2019 else x)\n",
    "\n",
    "df['release_day'] = df['release_date'].dt.day\n",
    "df['release_month'] = df['release_date'].dt.month\n",
    "df['release_year'] = df['release_date'].dt.year\n",
    "df['release_weekday'] = df['release_date'].dt.weekday\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_day_features = df[['release_day', 'release_month', 'release_year', 'release_weekday']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_day_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/holidays/countries/india.py:166: Warning: Diwali and Holi holidays available from 2001 to 2030 only\n",
      "  warnings.warn(warning_msg, Warning)\n"
     ]
    }
   ],
   "source": [
    "for country_code in country_codes:\n",
    "    check_if_is_holiday_in_country = partial(check_if_is_holiday, country_code=country_code)\n",
    "    release_day_features = np.concatenate((release_day_features, df['release_date'].apply(check_if_is_holiday_in_country).values.reshape(-1, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 17)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_day_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2516)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, release_day_features), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['runtime'].fillna(df['runtime'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2517)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, df['runtime'].values.reshape(-1, 1)), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 50)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = 'spoken_languages'\n",
    "\n",
    "convert(column)\n",
    "production_companies = [[str(o['iso_639_1']) for o in d]  for d in df[column].tolist()]\n",
    "feature_hasher = FeatureHasher(n_features=50, input_type=\"string\")\n",
    "production_companies_features = feature_hasher.transform(production_companies)  # can be id\n",
    "production_companies_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2567)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, production_companies_features.toarray()), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = df['status'].values\n",
    "status = status.reshape(-1, 1)\n",
    "\n",
    "status_ohe = OneHotEncoder(min_frequency=.005, sparse_output=False, handle_unknown='infrequent_if_exist').fit(status)\n",
    "status_ohe.transform(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2569)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, status_ohe.transform(status)), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tagline'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3337)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, multilingual_model.encode(df['tagline'].values)), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if contain nan\n",
    "df['title'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4105)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, multilingual_model.encode(df['title'].values)), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the keywords and sum them up\n",
    "column = 'Keywords'\n",
    "convert(column)\n",
    "embeddings = []\n",
    "keywords = ([str(o['name']) for o in d]  for d in df[column].tolist())\n",
    "for keyword in keywords:\n",
    "    embeddings.append(multilingual_model.encode(keyword).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(embeddings):\n",
    "    if len(e.shape) == 0:\n",
    "        embeddings[i] = np.zeros(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 768)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.stack(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4873)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, embeddings), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 120)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = 'cast'\n",
    "\n",
    "convert(column)\n",
    "production_companies = [[str(o['name']) for o in d]  for d in df[column].tolist()]\n",
    "feature_hasher = FeatureHasher(n_features=120, input_type=\"string\")\n",
    "production_companies_features = feature_hasher.transform(production_companies)\n",
    "production_companies_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4993)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, production_companies_features.toarray()), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 120)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = 'crew'\n",
    "\n",
    "convert(column)\n",
    "production_companies = [[str(o['name'])+'|'+str(o['job'])+'|'+str(o['department']) for o in d]  for d in df[column].tolist()]\n",
    "feature_hasher = FeatureHasher(n_features=120, input_type=\"string\")\n",
    "production_companies_features = feature_hasher.transform(production_companies)\n",
    "production_companies_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 5113)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((features, production_companies_features.toarray()), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features\n",
    "np.save('features_short_new.npy', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39m0\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "0/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['revenue'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nan in features\n",
    "np.isnan(features).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locate nan\n",
    "np.argwhere(np.isnan(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# use features for revenue prediction with xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, df['revenue'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 1000)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "print(\"RMSE: %f\" % (rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the root mean squared logarithmic error\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0697147322334315"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use random forest for revenue prediction\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "rmsle(y_test, preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ohe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ohe\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ohe' is not defined"
     ]
    }
   ],
   "source": [
    "original_language_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the vectorizers\n",
    "with open('status_ohe_short.pkl', 'wb') as f:\n",
    "    pickle.dump(status_ohe, f)\n",
    "\n",
    "with open('original_language_ohe_short.pkl', 'wb') as f:\n",
    "    pickle.dump(original_language_ohe, f)\n",
    "\n",
    "with open('genres_vectorizer_short.pkl', 'wb') as f:\n",
    "    pickle.dump(genres_vectorizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2637294</td>\n",
       "      <td>en</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>...</td>\n",
       "      <td>2/20/15</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
       "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
       "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
       "      <td>12314651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>en</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>...</td>\n",
       "      <td>8/6/04</td>\n",
       "      <td>113.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
       "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
       "      <td>95149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "      <td>tt2582802</td>\n",
       "      <td>en</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>...</td>\n",
       "      <td>10/10/14</td>\n",
       "      <td>105.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
       "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
       "      <td>13092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
       "      <td>http://kahaanithefilm.com/</td>\n",
       "      <td>tt1821480</td>\n",
       "      <td>hi</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>...</td>\n",
       "      <td>3/9/12</td>\n",
       "      <td>122.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
       "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
       "      <td>16000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt1380152</td>\n",
       "      <td>ko</td>\n",
       "      <td>마린보이</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>...</td>\n",
       "      <td>2/5/09</td>\n",
       "      <td>118.0</td>\n",
       "      <td>[{'iso_639_1': 'ko', 'name': '한국어/조선말'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marine Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
       "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
       "      <td>3923970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>2996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 10749, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0109403</td>\n",
       "      <td>en</td>\n",
       "      <td>Chasers</td>\n",
       "      <td>Military men Rock Reilly and Eddie Devane are ...</td>\n",
       "      <td>9.853270</td>\n",
       "      <td>...</td>\n",
       "      <td>4/22/94</td>\n",
       "      <td>102.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>It was supposed to be a routine prisoner trans...</td>\n",
       "      <td>Chasers</td>\n",
       "      <td>[{'id': 378, 'name': 'prison'}, {'id': 572, 'n...</td>\n",
       "      <td>[{'cast_id': 2, 'character': 'Rock Reilly', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe4494c3a368484e02ac7d', 'de...</td>\n",
       "      <td>1596687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10402, 'n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2364975</td>\n",
       "      <td>sv</td>\n",
       "      <td>Vi är bäst!</td>\n",
       "      <td>Three girls in 1980s Stockholm decide to form ...</td>\n",
       "      <td>3.727996</td>\n",
       "      <td>...</td>\n",
       "      <td>3/28/13</td>\n",
       "      <td>102.0</td>\n",
       "      <td>[{'iso_639_1': 'sv', 'name': 'svenska'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We Are the Best!</td>\n",
       "      <td>[{'id': 1192, 'name': 'sweden'}, {'id': 4470, ...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Bobo', 'credit_i...</td>\n",
       "      <td>[{'credit_id': '5716b72ac3a3686678012c84', 'de...</td>\n",
       "      <td>180590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 80, 'name': 'Crime'}, {'id': 28, 'name...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0116908</td>\n",
       "      <td>en</td>\n",
       "      <td>The Long Kiss Goodnight</td>\n",
       "      <td>Samantha Caine, suburban homemaker, is the ide...</td>\n",
       "      <td>14.482345</td>\n",
       "      <td>...</td>\n",
       "      <td>10/11/96</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>What's forgotten is not always gone.</td>\n",
       "      <td>The Long Kiss Goodnight</td>\n",
       "      <td>[{'id': 441, 'name': 'assassination'}, {'id': ...</td>\n",
       "      <td>[{'cast_id': 10, 'character': 'Samantha Caine ...</td>\n",
       "      <td>[{'credit_id': '52fe443a9251416c7502d579', 'de...</td>\n",
       "      <td>89456761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 10749, '...</td>\n",
       "      <td>http://www.alongcamepolly.com/</td>\n",
       "      <td>tt0343135</td>\n",
       "      <td>en</td>\n",
       "      <td>Along Came Polly</td>\n",
       "      <td>Reuben Feffer is a guy who's spent his entire ...</td>\n",
       "      <td>15.725542</td>\n",
       "      <td>...</td>\n",
       "      <td>1/16/04</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>For the most cautious man on Earth, life is ab...</td>\n",
       "      <td>Along Came Polly</td>\n",
       "      <td>[{'id': 966, 'name': 'beach'}, {'id': 2676, 'n...</td>\n",
       "      <td>[{'cast_id': 8, 'character': 'Reuben Feffer', ...</td>\n",
       "      <td>[{'credit_id': '556f817b9251410866000a63', 'de...</td>\n",
       "      <td>171963386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000000</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 28, 'n...</td>\n",
       "      <td>http://www.abductionthefilm.com/</td>\n",
       "      <td>tt1600195</td>\n",
       "      <td>en</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>A young man sets out to uncover the truth abou...</td>\n",
       "      <td>10.512109</td>\n",
       "      <td>...</td>\n",
       "      <td>9/22/11</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>They stole his life. He's taking it back.</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>[{'id': 591, 'name': 'cia'}, {'id': 822, 'name...</td>\n",
       "      <td>[{'cast_id': 2, 'character': 'Nathan Harper', ...</td>\n",
       "      <td>[{'credit_id': '5391990d0e0a260fb5001629', 'de...</td>\n",
       "      <td>82087155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                              belongs_to_collection    budget   \n",
       "0        1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000  \\\n",
       "1        2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
       "2        3                                                NaN   3300000   \n",
       "3        4                                                NaN   1200000   \n",
       "4        5                                                NaN         0   \n",
       "...    ...                                                ...       ...   \n",
       "2995  2996                                                NaN         0   \n",
       "2996  2997                                                NaN         0   \n",
       "2997  2998                                                NaN  65000000   \n",
       "2998  2999                                                NaN  42000000   \n",
       "2999  3000                                                NaN  35000000   \n",
       "\n",
       "                                                 genres   \n",
       "0                        [{'id': 35, 'name': 'Comedy'}]  \\\n",
       "1     [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "2                         [{'id': 18, 'name': 'Drama'}]   \n",
       "3     [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
       "4     [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
       "...                                                 ...   \n",
       "2995  [{'id': 35, 'name': 'Comedy'}, {'id': 10749, '...   \n",
       "2996  [{'id': 18, 'name': 'Drama'}, {'id': 10402, 'n...   \n",
       "2997  [{'id': 80, 'name': 'Crime'}, {'id': 28, 'name...   \n",
       "2998  [{'id': 35, 'name': 'Comedy'}, {'id': 10749, '...   \n",
       "2999  [{'id': 53, 'name': 'Thriller'}, {'id': 28, 'n...   \n",
       "\n",
       "                               homepage    imdb_id original_language   \n",
       "0                                   NaN  tt2637294                en  \\\n",
       "1                                   NaN  tt0368933                en   \n",
       "2     http://sonyclassics.com/whiplash/  tt2582802                en   \n",
       "3            http://kahaanithefilm.com/  tt1821480                hi   \n",
       "4                                   NaN  tt1380152                ko   \n",
       "...                                 ...        ...               ...   \n",
       "2995                                NaN  tt0109403                en   \n",
       "2996                                NaN  tt2364975                sv   \n",
       "2997                                NaN  tt0116908                en   \n",
       "2998     http://www.alongcamepolly.com/  tt0343135                en   \n",
       "2999   http://www.abductionthefilm.com/  tt1600195                en   \n",
       "\n",
       "                                original_title   \n",
       "0                       Hot Tub Time Machine 2  \\\n",
       "1     The Princess Diaries 2: Royal Engagement   \n",
       "2                                     Whiplash   \n",
       "3                                      Kahaani   \n",
       "4                                         마린보이   \n",
       "...                                        ...   \n",
       "2995                                   Chasers   \n",
       "2996                               Vi är bäst!   \n",
       "2997                   The Long Kiss Goodnight   \n",
       "2998                          Along Came Polly   \n",
       "2999                                 Abduction   \n",
       "\n",
       "                                               overview  popularity  ...   \n",
       "0     When Lou, who has become the \"father of the In...    6.575393  ...  \\\n",
       "1     Mia Thermopolis is now a college graduate and ...    8.248895  ...   \n",
       "2     Under the direction of a ruthless instructor, ...   64.299990  ...   \n",
       "3     Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936  ...   \n",
       "4     Marine Boy is the story of a former national s...    1.148070  ...   \n",
       "...                                                 ...         ...  ...   \n",
       "2995  Military men Rock Reilly and Eddie Devane are ...    9.853270  ...   \n",
       "2996  Three girls in 1980s Stockholm decide to form ...    3.727996  ...   \n",
       "2997  Samantha Caine, suburban homemaker, is the ide...   14.482345  ...   \n",
       "2998  Reuben Feffer is a guy who's spent his entire ...   15.725542  ...   \n",
       "2999  A young man sets out to uncover the truth abou...   10.512109  ...   \n",
       "\n",
       "     release_date runtime                                   spoken_languages   \n",
       "0         2/20/15    93.0           [{'iso_639_1': 'en', 'name': 'English'}]  \\\n",
       "1          8/6/04   113.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2        10/10/14   105.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3          3/9/12   122.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "4          2/5/09   118.0           [{'iso_639_1': 'ko', 'name': '한국어/조선말'}]   \n",
       "...           ...     ...                                                ...   \n",
       "2995      4/22/94   102.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2996      3/28/13   102.0           [{'iso_639_1': 'sv', 'name': 'svenska'}]   \n",
       "2997     10/11/96   120.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2998      1/16/04    90.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2999      9/22/11   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "        status                                            tagline   \n",
       "0     Released  The Laws of Space and Time are About to be Vio...  \\\n",
       "1     Released  It can take a lifetime to find true love; she'...   \n",
       "2     Released    The road to greatness can take you to the edge.   \n",
       "3     Released                                                NaN   \n",
       "4     Released                                                NaN   \n",
       "...        ...                                                ...   \n",
       "2995  Released  It was supposed to be a routine prisoner trans...   \n",
       "2996  Released                                                NaN   \n",
       "2997  Released               What's forgotten is not always gone.   \n",
       "2998  Released  For the most cautious man on Earth, life is ab...   \n",
       "2999  Released          They stole his life. He's taking it back.   \n",
       "\n",
       "                                         title   \n",
       "0                       Hot Tub Time Machine 2  \\\n",
       "1     The Princess Diaries 2: Royal Engagement   \n",
       "2                                     Whiplash   \n",
       "3                                      Kahaani   \n",
       "4                                   Marine Boy   \n",
       "...                                        ...   \n",
       "2995                                   Chasers   \n",
       "2996                          We Are the Best!   \n",
       "2997                   The Long Kiss Goodnight   \n",
       "2998                          Along Came Polly   \n",
       "2999                                 Abduction   \n",
       "\n",
       "                                               Keywords   \n",
       "0     [{'id': 4379, 'name': 'time travel'}, {'id': 9...  \\\n",
       "1     [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
       "2     [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
       "3     [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "2995  [{'id': 378, 'name': 'prison'}, {'id': 572, 'n...   \n",
       "2996  [{'id': 1192, 'name': 'sweden'}, {'id': 4470, ...   \n",
       "2997  [{'id': 441, 'name': 'assassination'}, {'id': ...   \n",
       "2998  [{'id': 966, 'name': 'beach'}, {'id': 2676, 'n...   \n",
       "2999  [{'id': 591, 'name': 'cia'}, {'id': 822, 'name...   \n",
       "\n",
       "                                                   cast   \n",
       "0     [{'cast_id': 4, 'character': 'Lou', 'credit_id...  \\\n",
       "1     [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
       "2     [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
       "3     [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
       "4     [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
       "...                                                 ...   \n",
       "2995  [{'cast_id': 2, 'character': 'Rock Reilly', 'c...   \n",
       "2996  [{'cast_id': 5, 'character': 'Bobo', 'credit_i...   \n",
       "2997  [{'cast_id': 10, 'character': 'Samantha Caine ...   \n",
       "2998  [{'cast_id': 8, 'character': 'Reuben Feffer', ...   \n",
       "2999  [{'cast_id': 2, 'character': 'Nathan Harper', ...   \n",
       "\n",
       "                                                   crew    revenue  \n",
       "0     [{'credit_id': '59ac067c92514107af02c8c8', 'de...   12314651  \n",
       "1     [{'credit_id': '52fe43fe9251416c7502563d', 'de...   95149435  \n",
       "2     [{'credit_id': '54d5356ec3a3683ba0000039', 'de...   13092000  \n",
       "3     [{'credit_id': '52fe48779251416c9108d6eb', 'de...   16000000  \n",
       "4     [{'credit_id': '52fe464b9251416c75073b43', 'de...    3923970  \n",
       "...                                                 ...        ...  \n",
       "2995  [{'credit_id': '52fe4494c3a368484e02ac7d', 'de...    1596687  \n",
       "2996  [{'credit_id': '5716b72ac3a3686678012c84', 'de...     180590  \n",
       "2997  [{'credit_id': '52fe443a9251416c7502d579', 'de...   89456761  \n",
       "2998  [{'credit_id': '556f817b9251410866000a63', 'de...  171963386  \n",
       "2999  [{'credit_id': '5391990d0e0a260fb5001629', 'de...   82087155  \n",
       "\n",
       "[3000 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
